
# ğŸ¤– PDF ChatBot with LangChain, Chroma & Gradio

A **local Retrieval-Augmented Generation (RAG) application** that allows you to **upload a PDF** and ask **natural-language questions** about its content.  
The system uses **semantic search + an open-source LLM** to generate **accurate, context-aware answers**.

---

## âœ¨ Key Features

- ğŸ“„ **Upload any PDF** and query its content  
- ğŸ” **Semantic retrieval** using **ChromaDB**  
- ğŸ§  **Local open-source LLM** (Flan-T5)  
- ğŸ’¬ **Multi-turn conversation memory**  
- ğŸ›ï¸ **Adjustable chunk size** for better retrieval quality  
- ğŸ–¥ï¸ **Simple web UI** built with **Gradio**  
- ğŸ” **No external APIs** â€“ runs fully **offline**

---

## ğŸ—ï¸ Architecture Overview

**Pipeline flow:**

1. **PDF upload**
2. Text extraction with **pdfplumber**
3. Chunking via **RecursiveCharacterTextSplitter**
4. Embedding with **Sentence-Transformers (MiniLM)**
5. Vector storage in **Chroma**
6. **Retrieval-Augmented Generation** using **LangChain RetrievalQA**
7. Answer generation with **Flan-T5**

---

## ğŸ§  How It Works (High Level)

- The PDF is converted into **overlapping text chunks**
- Each chunk is transformed into a **dense vector embedding**
- Chunks are stored in **Chroma** (in-memory vector database)
- User queries are embedded and **matched semantically**
- Retrieved context is **injected into the LLM prompt**
- The model generates a **grounded, context-aware answer**

---

## ğŸš€ Possible Improvements

- âœ… Persistent **Chroma** storage  
- âœ… **Session-based state** (multi-user)  
- âœ… **FastAPI backend**  
- âœ… **Docker & Cloud Run** deployment  
- âœ… **Agent-based RAG**  
- âœ… **Streaming responses**

---

## ğŸ“Œ Tech Stack

- **Python 3.9+**
- **LangChain**
- **ChromaDB**
- **Transformers**
- **Sentence-Transformers**
- **Gradio**
- **pdfplumber**

---

## ğŸ§‘â€ğŸ’» Author

Built as a **hands-on RAG learning project** to understand:  
**document ingestion, semantic search, and LLM-based QA pipelines**.

